# Gemini in Zed Past Prep

This document explains how Google Gemini powers core user experiences in the app and how to configure it safely in each environment.

Gemini is used in three main places. First, it acts as an essay and short‑answer grading fallback: when no external grading API is configured, the app calls Gemini to mark long answers against the marking guide and return structured scores and feedback. Second, it powers exam review explanations on the exam completion screen, where students can ask for step‑by‑step breakdowns of questions they got wrong. Third, it drives the study assistant chat, an in‑app tutor that answers syllabus‑aligned questions and explains topics in simple language.

All of these features call the Gemini API directly from the frontend using the `gemini-2.5-flash` model. For any Gemini‑powered functionality to work, you must configure an API key via the `VITE_GEMINI_API_KEY` environment variable. When this key is missing, the UI disables Gemini features gracefully and shows friendly messages instead of failing at runtime.

For configuration, the app expects a Google AI Studio / Gemini API key exposed as `VITE_GEMINI_API_KEY`. During local development this should be set in a `.env.local` (or `.env`) file in the project root, while production deployments (for example, on Vercel) should define the same variable in the platform’s environment settings. All calls use the Google Generative Language REST API, with the base URL `https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent` and the API key passed as a `?key=` query parameter.

When the primary essay‑grading API is not configured, the app falls back to the `gradeEssayWithGemini` helper in [src/services/essayGradingService.ts](../src/services/essayGradingService.ts). This function builds a detailed system prompt that positions Gemini as an experienced Zambian exam marker, instructs it to follow the provided marking guide, and requires it to return only JSON that matches a strict interface. A separate user prompt then provides the question, marking guide, student answer, and marking rules. The response is parsed from the `candidates[0].content.parts` array, the JSON is validated and clamped to the allowed mark range, and a `GradeEssayResponse` is returned. If the Gemini key is missing, a structured `NO_GEMINI_API_KEY` error is returned instead of attempting the call.

On the exam completion screen, implemented in [src/pages/ExamComplete.tsx](../src/pages/ExamComplete.tsx), students can request tailored explanations for each incorrect question via an “Ask Gemini to explain” action. The page computes which questions were answered incorrectly and, for each one, builds a rich prompt describing the paper, question text, options, student answer, and correct answer. A dedicated system prompt frames Gemini as a helpful exam tutor for Zambian students and asks for clear, step‑by‑step explanations that focus on why the correct answer is right and what to remember for next time. Responses are concatenated from the candidate parts, cleaned for display, and stored per question. If configuration is missing, the feature writes a clear information message instead of attempting the API call.

The study assistant on [src/pages/Study.tsx](../src/pages/Study.tsx) uses Gemini to provide an interactive tutor experience. It first loads the student’s profile from Supabase to personalise responses with name, grade, and school, then lets the user select a grade level, subject, and topic. These selections, along with any available study notes, are woven into a system prompt that instructs Gemini to act as a syllabus‑aligned assistant for Zambian students using Zed Past Prep. Each new question is sent together with a short conversation history summary, and Gemini’s replies are cleaned and added back into the chat log. Configuration errors or API failures are caught and surfaced as friendly chat messages rather than raw error output.

To add new Gemini‑powered features, follow these existing patterns. Always read `import.meta.env.VITE_GEMINI_API_KEY` and handle the “not configured” case explicitly. Design a clear prompt contract: for structured output, define and document the expected JSON shape; for explanations, keep prompts focused on the outcome you want for the learner. Reuse the shared `gemini-2.5-flash` model and the same text‑extraction and cleaning pipeline, and validate all critical fields in responses before trusting them. This keeps new integrations consistent, predictable, and easy to reason about across the codebase.